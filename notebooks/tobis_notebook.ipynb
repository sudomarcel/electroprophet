{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eccdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8913924",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = WeatherEnergy(limit=-1,\n",
    "#                     offset=0,\n",
    "#                     refine='Hauts-de-France',\n",
    "#                     target = \"eolien\",\n",
    "#                     city=['Heudicourt', 'Bucy-les-Pierrepont', 'Riencourt'],\n",
    "#                     years=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb331c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "class WeatherEnergy:\n",
    "    def __init__(self, limit:int, offset:int, refine:str, city:list ,target:str, years=10):\n",
    "        self.city = city\n",
    "        self.years = years\n",
    "        self.limit = limit\n",
    "        self.offset = offset\n",
    "        self.refine = refine\n",
    "        self.target = target\n",
    "\n",
    "    def get_city_lonlan(self):\n",
    "        '''\n",
    "        This function receives the name of the city list and returns the lat and lon of that city\n",
    "        in a dictionary\n",
    "        '''\n",
    "\n",
    "        # Create a geolocator object\n",
    "        geolocator = Nominatim(user_agent=\"my_app\")\n",
    "\n",
    "        #save the coordinates of each city in self.city in a dictionary\n",
    "        coordinates = {}\n",
    "        for city in self.city:\n",
    "            # Get the location of the city\n",
    "            location = geolocator.geocode(city)\n",
    "\n",
    "            #check if the location exists\n",
    "            if location:\n",
    "                lat, lon = location.latitude, location.longitude # Extract the latitude and longitude\n",
    "                coordinates[city] = [lat,lon]\n",
    "            else:\n",
    "                print(f\"Could not retrieve coordinates for {city}\")\n",
    "\n",
    "        return coordinates\n",
    "\n",
    "    def get_weather(self):\n",
    "\n",
    "        '''\n",
    "        This function receives the name of the city list and a number of years, and returns a dataframe\n",
    "        with the average of the weather data from these city list during those past years\n",
    "        '''\n",
    "\n",
    "        # First we declare the weather parameters. Here we'll be taking all params supported by the API\n",
    "        weather_params = ['temperature_2m','relativehumidity_2m','dewpoint_2m',\n",
    "                      'apparent_temperature','pressure_msl','surface_pressure',\n",
    "                      'precipitation','rain','snowfall','cloudcover',\n",
    "                      'cloudcover_low','cloudcover_mid','cloudcover_high',\n",
    "                      'shortwave_radiation','direct_radiation','direct_normal_irradiance',\n",
    "                      'diffuse_radiation','windspeed_10m','windspeed_100m',\n",
    "                      'winddirection_10m','winddirection_100m','windgusts_10m',\n",
    "                      'et0_fao_evapotranspiration','weathercode','vapor_pressure_deficit',\n",
    "                      'soil_temperature_0_to_7cm','soil_temperature_7_to_28cm',\n",
    "                      'soil_temperature_28_to_100cm','soil_temperature_100_to_255cm',\n",
    "                      'soil_moisture_0_to_7cm','soil_moisture_7_to_28cm',\n",
    "                      'soil_moisture_28_to_100cm','soil_moisture_100_to_255cm']\n",
    "\n",
    "        # Then we compute the dates used to get the weather data\n",
    "        ## The API only has data until 9 days ago\n",
    "        end_date = (date.today() - relativedelta(days=8)).strftime('%Y-%m-%d')\n",
    "        #start_date = (datetime.date.today() - relativedelta(years=years)).strftime('%Y-%m-%d')\n",
    "        start_date = (date.today() - relativedelta(years=self.years)).strftime('%Y-%m-%d')\n",
    "\n",
    "        #call the method to receive the coordinates from the self.city list\n",
    "        coordinates = self.get_city_lonlan()\n",
    "        #create an empty dataframe\n",
    "        weather_df_full = pd.DataFrame(columns=weather_params)\n",
    "        cities = []\n",
    "        #create a dataframe with weather params for each city and store in the list cities\n",
    "        for city in self.city:\n",
    "            lat = coordinates[city][0]\n",
    "            lan = coordinates[city][1]\n",
    "\n",
    "        # So we make the request to the weather API archive\n",
    "            weather_response= requests.get('https://archive-api.open-meteo.com/v1/archive',\n",
    "                            params = {'latitude': lat,\n",
    "                                        'longitude': lan,\n",
    "                                        'start_date': start_date,\n",
    "                                        'end_date': end_date,\n",
    "                                        'hourly': weather_params,\n",
    "                                        'timezone': 'auto'}).json()\n",
    "            weather_df = pd.DataFrame(weather_response['hourly'], columns = ['time'] + weather_params)\n",
    "            weather_df['time'] = pd.to_datetime(weather_df['time'], format='%Y-%m-%d')\n",
    "            weather_df = weather_df.set_index('time')\n",
    "\n",
    "            # Format float to 1 decimal, sum the 3 tables and return the average\n",
    "            pd.options.display.float_format = \"{:,.1f}\".format\n",
    "            cities.append(weather_df)\n",
    "\n",
    "        #add the dataframes from the list cities to one dataframe(on the same index which is time)\n",
    "        x=0\n",
    "        for df in cities:\n",
    "            if x==0:\n",
    "                weather_df_full=df\n",
    "                x=1\n",
    "            else:\n",
    "                weather_df_full=weather_df_full.add(df)\n",
    "\n",
    "        #divide each row by the lengths of the city list, so we have an average\n",
    "        weather_df_full = weather_df_full /len(self.city)\n",
    "\n",
    "        return weather_df_full\n",
    "\n",
    "    def get_energy_production(self):\n",
    "\n",
    "        '''\n",
    "        This function receives the name of a region, a limit and an offset, and returns a dataframe\n",
    "        with energy production data from this region\n",
    "        '''\n",
    "\n",
    "        #params to pass into the requests\n",
    "        params = {'limit': self.limit, 'offset': self.offset, 'refine': f'libelle_region:{self.refine}'}\n",
    "\n",
    "        #request the API for the data from 2013-2022\n",
    "        url_2013_2022 = 'https://odre.opendatasoft.com/api/v2/catalog/datasets/eco2mix-regional-cons-def/exports/json'\n",
    "        response_2013_2022 = requests.get(url=url_2013_2022,params = params).json()\n",
    "\n",
    "        #transform API request into a dataframe\n",
    "        df_2013_2022 = pd.DataFrame(response_2013_2022)\n",
    "\n",
    "        #request the API for the data from 2022-today\n",
    "        url_2022_today = 'https://odre.opendatasoft.com/api/v2/catalog/datasets/eco2mix-regional-tr/exports/json'\n",
    "        response_2022_today = requests.get(url=url_2022_today,params = params).json()\n",
    "\n",
    "        #transform API request into a dataframe\n",
    "        df_2022_today = pd.DataFrame(response_2022_today)\n",
    "\n",
    "        #merge those two together on just columns that exist in the first one\n",
    "        energy_production_df = pd.concat([df_2013_2022, df_2022_today], sort=False,join=\"inner\")\n",
    "\n",
    "        #transform the column \"date_heure\", so that it is compatible with the weather data\n",
    "        energy_production_df.insert(0, \"time\", energy_production_df['date'] + ' ' + energy_production_df['heure'])\n",
    "        energy_production_df['time'] =  pd.to_datetime(energy_production_df['time'])\n",
    "        energy_production_df = energy_production_df.sort_values('time')\n",
    "        energy_production_df = energy_production_df.set_index('time')\n",
    "\n",
    "        return energy_production_df\n",
    "\n",
    "    def merged(self):\n",
    "\n",
    "        '''\n",
    "        This function takes in the get_weather and the get_energy_production dataframes\n",
    "        and merges them into a merged_df dataframe\n",
    "        '''\n",
    "\n",
    "        #calls the get_weather function and stores the result in a dataframe\n",
    "        weather_df = self.get_weather()\n",
    "\n",
    "        #calls the get_energy_production and stores the result in a dataframe\n",
    "        energy_production_df = self.get_energy_production()\n",
    "\n",
    "        #merges the two dataframes and returns the merged_df\n",
    "        merged_df = pd.merge(weather_df, energy_production_df[self.target], left_index=True, right_index=True)\n",
    "        merged_df = merged_df[merged_df[self.target].notna()]\n",
    "\n",
    "        return merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f699fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = WeatherEnergy(limit=-1,\n",
    "                     offset=0,\n",
    "                     refine='Hauts-de-France',\n",
    "                     target = \"eolien\",\n",
    "                     city=['Heudicourt'],\n",
    "                     years=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b7bff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = data.merged()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f490274f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged_df.to_csv(\"/Users/trustler/Desktop/merged_df1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885f06b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"/Users/trustler/Desktop/merged_df1.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23121a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged_df.hist(figsize=(20, 20), grid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70a32cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, PowerTransformer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class FeaturePreprocessing:\n",
    "    def __init__(self,df):\n",
    "        self.df = df\n",
    "\n",
    "    def get_wind_components(self):\n",
    "\n",
    "        # Convert degrees to radians and store the values into wd_rad\n",
    "        #wind direction 10 m\n",
    "        wd_rad_10 = self.df.pop('winddirection_10m')*np.pi / 180\n",
    "\n",
    "        #wind direction 100 m\n",
    "        wd_rad_100 = self.df.pop('winddirection_100m')*np.pi / 180\n",
    "\n",
    "        # Calculate the wind x and y components and store then in two new columns\n",
    "        # `Wx` and `Wy`\n",
    "        #wind speed 10 m\n",
    "        wv_10 = self.df.pop('windspeed_10m')\n",
    "        self.df['Wx_10'] = wv_10*np.cos(wd_rad_10)\n",
    "        self.df['Wy_10'] = wv_10*np.sin(wd_rad_10)\n",
    "\n",
    "        #wind speed 100 m\n",
    "        wv_100 = self.df.pop('windspeed_100m')\n",
    "        self.df['Wx_100'] = wv_100*np.cos(wd_rad_100)\n",
    "        self.df['Wy_100'] = wv_100*np.sin(wd_rad_100)\n",
    "\n",
    "        return self.df\n",
    "\n",
    "    def feature_processing(self):\n",
    "        #has to acces the get_wind_components so change\n",
    "        #columns to use\n",
    "\n",
    "        unprocessed_dataframe = self.get_wind_components()\n",
    "        columns_for_standardscaler = ['temperature_2m','dewpoint_2m',\n",
    "                                    'apparent_temperature','pressure_msl','surface_pressure',\n",
    "                                    'Wx_10','Wx_100','Wy_10',\n",
    "                                    'Wy_100','windgusts_10m','soil_temperature_0_to_7cm',\n",
    "                                    'soil_temperature_7_to_28cm','soil_temperature_28_to_100cm',\n",
    "                                    'soil_temperature_100_to_255cm','soil_moisture_0_to_7cm',\n",
    "                                    'soil_moisture_7_to_28cm','soil_moisture_28_to_100cm',\n",
    "                                    'soil_moisture_100_to_255cm']\n",
    "\n",
    "        columns_for_robustscaler = ['cloudcover','cloudcover_low',\n",
    "                                    'cloudcover_mid','cloudcover_high']\n",
    "\n",
    "        columns_for_powertransformer = ['relativehumidity_2m','precipitation','rain',\n",
    "                                        'snowfall', 'shortwave_radiation','direct_radiation',\n",
    "                                        'direct_normal_irradiance','diffuse_radiation',\n",
    "                                        'et0_fao_evapotranspiration','vapor_pressure_deficit']\n",
    "\n",
    "        #function doesnt work like this\n",
    "        scaler = make_column_transformer(\n",
    "            (StandardScaler(),columns_for_standardscaler),\n",
    "            (RobustScaler(),columns_for_robustscaler),\n",
    "            (PowerTransformer(),columns_for_powertransformer))\n",
    "\n",
    "        scaled_data = scaler.fit_transform(unprocessed_dataframe)\n",
    "        scaled_dataframe = pd.DataFrame(scaled_data, columns=scaler.get_feature_names_out())\n",
    "        processed_dataframe = scaled_dataframe.set_index(unprocessed_dataframe.index)\n",
    "        return processed_dataframe\n",
    "\n",
    "    def get_season(self):\n",
    "        \"\"\"\n",
    "        Calls a function data gets the day from the time column,\n",
    "        outputs whether the day is in the Spring, Summer, Fall or\n",
    "        Winter and creates\n",
    "        \"\"\"\n",
    "        processed_dataframe = self.feature_processing()\n",
    "        season = []\n",
    "\n",
    "        # get the current day of the year\n",
    "        doy = processed_dataframe.iloc[0].name.timetuple().tm_yday\n",
    "\n",
    "        # \"day of year\" ranges for the northern hemisphere\n",
    "        spring = range(80, 172)\n",
    "        summer = range(172, 264)\n",
    "        fall = range(264, 355)\n",
    "        # winter = everything else\n",
    "\n",
    "        for doy in range(len(processed_dataframe)):\n",
    "            if doy in spring:\n",
    "                season.append('Spring')\n",
    "            elif doy in summer:\n",
    "                season.append('Summer')\n",
    "            elif doy in fall:\n",
    "                season.append('Fall')\n",
    "            else:\n",
    "                season.append('Winter')\n",
    "\n",
    "        processed_dataframe['season'] = season\n",
    "        processed_dataframe = processed_dataframe.join(pd.get_dummies(processed_dataframe['season'], prefix='season'))\n",
    "        processed_dataframe.drop('season', axis=1, inplace=True)\n",
    "        return processed_dataframe\n",
    "\n",
    "\n",
    "    #Returns if the day is a weekday or not\n",
    "    def get_weekday(self):\n",
    "        processed_dataframe = self.get_season()\n",
    "\n",
    "        weekday = []\n",
    "\n",
    "        for day in range(len(processed_dataframe)):\n",
    "            if processed_dataframe.iloc[day].name.weekday() < 5:\n",
    "                weekday.append('Weekday')\n",
    "            else:  # 5 Sat, 6 Sun\n",
    "                weekday.append('Weekend')\n",
    "\n",
    "        processed_dataframe['weekday'] = weekday\n",
    "        processed_dataframe = processed_dataframe.join(pd.get_dummies(processed_dataframe['weekday'], prefix='weekday'))\n",
    "        processed_dataframe.drop('weekday', axis=1, inplace=True)\n",
    "        return processed_dataframe\n",
    "\n",
    "    #Returns the period of the day for each row\n",
    "    def get_period_day(self):\n",
    "\n",
    "        processed_dataframe = self.get_weekday()\n",
    "        period = []\n",
    "\n",
    "        for day in range(len(processed_dataframe)):\n",
    "            if 4 <= processed_dataframe.iloc[day].name.hour <= 11:\n",
    "                period.append('Morning')\n",
    "            elif 12 <= processed_dataframe.iloc[day].name.hour <= 19:\n",
    "                period.append('Afternoon')\n",
    "            else:\n",
    "                period.append('Night')\n",
    "\n",
    "        processed_dataframe['period'] = period\n",
    "        processed_dataframe = processed_dataframe.join(pd.get_dummies(processed_dataframe['period'], prefix='period'))\n",
    "        processed_dataframe.drop('period', axis=1, inplace=True)\n",
    "        return processed_dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d64689",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_data = FeaturePreprocessing(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544372f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_period_day = preprocessing_data.get_period_day()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ece57cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_period_day.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9754e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_period_day.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b30fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_period_day.hist(figsize=(20, 20), grid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df03780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26babc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "class WeatherEnergy:\n",
    "    def __init__(self, limit:int, offset:int, refine:str, city:list ,target:str, years=10):\n",
    "        self.city = city\n",
    "        self.years = years\n",
    "        self.limit = limit\n",
    "        self.offset = offset\n",
    "        self.refine = refine\n",
    "        self.target = target\n",
    "\n",
    "    def get_city_lonlan(self):\n",
    "        '''\n",
    "        This function receives the name of the city list and returns the lat and lon of that city\n",
    "        in a dictionary\n",
    "        '''\n",
    "\n",
    "        # Create a geolocator object\n",
    "        geolocator = Nominatim(user_agent=\"my_app\")\n",
    "\n",
    "        #save the coordinates of each city in self.city in a dictionary\n",
    "        coordinates = {}\n",
    "        for city in self.city:\n",
    "            # Get the location of the city\n",
    "            location = geolocator.geocode(city)\n",
    "\n",
    "            #check if the location exists\n",
    "            if location:\n",
    "                lat, lon = location.latitude, location.longitude # Extract the latitude and longitude\n",
    "                coordinates[city] = [lat,lon]\n",
    "            else:\n",
    "                print(f\"Could not retrieve coordinates for {city}\")\n",
    "\n",
    "        return coordinates\n",
    "\n",
    "    def get_weather(self):\n",
    "\n",
    "        '''\n",
    "        This function receives the name of the city list and a number of years, and returns a dataframe\n",
    "        with the average of the weather data from these city list during those past years\n",
    "        '''\n",
    "\n",
    "        # First we declare the weather parameters. Here we'll be taking all params supported by the API\n",
    "        weather_params = ['temperature_2m','relativehumidity_2m','dewpoint_2m',\n",
    "                      'apparent_temperature','pressure_msl','surface_pressure',\n",
    "                      'precipitation','rain','snowfall','cloudcover',\n",
    "                      'cloudcover_low','cloudcover_mid','cloudcover_high',\n",
    "                      'shortwave_radiation','direct_radiation','direct_normal_irradiance',\n",
    "                      'diffuse_radiation','windspeed_10m','windspeed_100m',\n",
    "                      'winddirection_10m','winddirection_100m','windgusts_10m',\n",
    "                      'et0_fao_evapotranspiration','weathercode','vapor_pressure_deficit',\n",
    "                      'soil_temperature_0_to_7cm','soil_temperature_7_to_28cm',\n",
    "                      'soil_temperature_28_to_100cm','soil_temperature_100_to_255cm',\n",
    "                      'soil_moisture_0_to_7cm','soil_moisture_7_to_28cm',\n",
    "                      'soil_moisture_28_to_100cm','soil_moisture_100_to_255cm']\n",
    "\n",
    "        # Then we compute the dates used to get the weather data\n",
    "        ## The API only has data until 9 days ago\n",
    "        end_date = (date.today() - relativedelta(days=8)).strftime('%Y-%m-%d')\n",
    "        #start_date = (datetime.date.today() - relativedelta(years=years)).strftime('%Y-%m-%d')\n",
    "        start_date = (date.today() - relativedelta(years=self.years)).strftime('%Y-%m-%d')\n",
    "\n",
    "        #call the method to receive the coordinates from the self.city list\n",
    "        coordinates = self.get_city_lonlan()\n",
    "        #create an empty dataframe\n",
    "        weather_df_full = pd.DataFrame(columns=weather_params)\n",
    "        cities = []\n",
    "        #create a dataframe with weather params for each city and store in the list cities\n",
    "        for city in self.city:\n",
    "            lat = coordinates[city][0]\n",
    "            lan = coordinates[city][1]\n",
    "\n",
    "        # So we make the request to the weather API archive\n",
    "            weather_response= requests.get('https://archive-api.open-meteo.com/v1/archive',\n",
    "                            params = {'latitude': lat,\n",
    "                                        'longitude': lan,\n",
    "                                        'start_date': start_date,\n",
    "                                        'end_date': end_date,\n",
    "                                        'hourly': weather_params,\n",
    "                                        'timezone': 'auto'}).json()\n",
    "            weather_df = pd.DataFrame(weather_response['hourly'], columns = ['time'] + weather_params)\n",
    "            weather_df['time'] = pd.to_datetime(weather_df['time'], format='%Y-%m-%d')\n",
    "            weather_df = weather_df.set_index('time')\n",
    "\n",
    "            # Format float to 1 decimal, sum the 3 tables and return the average\n",
    "            pd.options.display.float_format = \"{:,.1f}\".format\n",
    "            cities.append(weather_df)\n",
    "\n",
    "        #add the dataframes from the list cities to one dataframe(on the same index which is time)\n",
    "        x=0\n",
    "        for df in cities:\n",
    "            if x==0:\n",
    "                weather_df_full=df\n",
    "                x=1\n",
    "            else:\n",
    "                weather_df_full=weather_df_full.add(df)\n",
    "\n",
    "        #divide each row by the lengths of the city list, so we have an average\n",
    "        weather_df_full = weather_df_full /len(self.city)\n",
    "\n",
    "        return weather_df_full\n",
    "\n",
    "    def get_energy_production(self):\n",
    "\n",
    "        '''\n",
    "        This function receives the name of a region, a limit and an offset, and returns a dataframe\n",
    "        with energy production data from this region\n",
    "        '''\n",
    "\n",
    "        #params to pass into the requests\n",
    "        params = {'limit': self.limit, 'offset': self.offset, 'refine': f'libelle_region:{self.refine}'}\n",
    "\n",
    "        #request the API for the data from 2013-2022\n",
    "        url_2013_2022 = 'https://odre.opendatasoft.com/api/v2/catalog/datasets/eco2mix-regional-cons-def/exports/json'\n",
    "        response_2013_2022 = requests.get(url=url_2013_2022,params = params).json()\n",
    "\n",
    "        #transform API request into a dataframe\n",
    "        df_2013_2022 = pd.DataFrame(response_2013_2022)\n",
    "\n",
    "        #request the API for the data from 2022-today\n",
    "        url_2022_today = 'https://odre.opendatasoft.com/api/v2/catalog/datasets/eco2mix-regional-tr/exports/json'\n",
    "        response_2022_today = requests.get(url=url_2022_today,params = params).json()\n",
    "\n",
    "        #transform API request into a dataframe\n",
    "        df_2022_today = pd.DataFrame(response_2022_today)\n",
    "\n",
    "        #merge those two together on just columns that exist in the first one\n",
    "        energy_production_df = pd.concat([df_2013_2022, df_2022_today], sort=False,join=\"inner\")\n",
    "\n",
    "        #transform the column \"date_heure\", so that it is compatible with the weather data\n",
    "        energy_production_df.insert(0, \"time\", energy_production_df['date'] + ' ' + energy_production_df['heure'])\n",
    "        energy_production_df['time'] =  pd.to_datetime(energy_production_df['time'])\n",
    "        energy_production_df = energy_production_df.sort_values('time')\n",
    "        energy_production_df = energy_production_df.set_index('time')\n",
    "\n",
    "        return energy_production_df\n",
    "\n",
    "    def merged(self):\n",
    "\n",
    "        '''\n",
    "        This function takes in the get_weather and the get_energy_production dataframes\n",
    "        and merges them into a merged_df dataframe\n",
    "        '''\n",
    "\n",
    "        #calls the get_weather function and stores the result in a dataframe\n",
    "        weather_df = self.get_weather()\n",
    "\n",
    "        #calls the get_energy_production and stores the result in a dataframe\n",
    "        energy_production_df = self.get_energy_production()\n",
    "\n",
    "        #merges the two dataframes and returns the merged_df\n",
    "        merged_df = pd.merge(weather_df, energy_production_df[self.target], left_index=True, right_index=True)\n",
    "        merged_df = merged_df[merged_df[self.target].notna()]\n",
    "\n",
    "        return merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98445fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, PowerTransformer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class FeaturePreprocessing:\n",
    "    def __init__(self,df,target):\n",
    "        self.df = df\n",
    "        self.target = df[target]\n",
    "\n",
    "    def get_wind_components(self):\n",
    "\n",
    "\n",
    "        # Convert degrees to radians and store the values into wd_rad\n",
    "        #wind direction 10 m\n",
    "        wd_rad_10 = self.df.pop('winddirection_10m')*np.pi / 180\n",
    "\n",
    "        #wind direction 100 m\n",
    "        wd_rad_100 = self.df.pop('winddirection_100m')*np.pi / 180\n",
    "\n",
    "        # Calculate the wind x and y components and store then in two new columns\n",
    "        # `Wx` and `Wy`\n",
    "        #wind speed 10 m\n",
    "        wv_10 = self.df.pop('windspeed_10m')\n",
    "        self.df['Wx_10'] = wv_10*np.cos(wd_rad_10)\n",
    "        self.df['Wy_10'] = wv_10*np.sin(wd_rad_10)\n",
    "\n",
    "        #wind speed 100 m\n",
    "        wv_100 = self.df.pop('windspeed_100m')\n",
    "        self.df['Wx_100'] = wv_100*np.cos(wd_rad_100)\n",
    "        self.df['Wy_100'] = wv_100*np.sin(wd_rad_100)\n",
    "\n",
    "        return self.df\n",
    "\n",
    "    def feature_processing(self):\n",
    "        #has to acces the get_wind_components so change\n",
    "        #columns to use\n",
    "\n",
    "        unprocessed_dataframe = self.get_wind_components()\n",
    "        columns_for_standardscaler = ['temperature_2m','dewpoint_2m',\n",
    "                                    'apparent_temperature','pressure_msl','surface_pressure',\n",
    "                                    'Wx_10','Wx_100','Wy_10',\n",
    "                                    'Wy_100','windgusts_10m','soil_temperature_0_to_7cm',\n",
    "                                    'soil_temperature_7_to_28cm','soil_temperature_28_to_100cm',\n",
    "                                    'soil_temperature_100_to_255cm','soil_moisture_0_to_7cm',\n",
    "                                    'soil_moisture_7_to_28cm','soil_moisture_28_to_100cm',\n",
    "                                    'soil_moisture_100_to_255cm']\n",
    "\n",
    "        columns_for_robustscaler = ['cloudcover','cloudcover_low',\n",
    "                                    'cloudcover_mid','cloudcover_high']\n",
    "\n",
    "        columns_for_powertransformer = ['relativehumidity_2m','precipitation','rain',\n",
    "                                        'snowfall', 'shortwave_radiation','direct_radiation',\n",
    "                                        'direct_normal_irradiance','diffuse_radiation',\n",
    "                                        'et0_fao_evapotranspiration','vapor_pressure_deficit']\n",
    "\n",
    "        #function doesnt work like this\n",
    "        scaler = make_column_transformer(\n",
    "            (StandardScaler(),columns_for_standardscaler),\n",
    "            (RobustScaler(),columns_for_robustscaler),\n",
    "            (PowerTransformer(),columns_for_powertransformer))\n",
    "\n",
    "        scaled_data = scaler.fit_transform(unprocessed_dataframe)\n",
    "        scaled_dataframe = pd.DataFrame(scaled_data, columns=scaler.get_feature_names_out())\n",
    "        processed_dataframe = scaled_dataframe.set_index(unprocessed_dataframe.index)\n",
    "        return processed_dataframe\n",
    "\n",
    "    def get_season(self):\n",
    "        \"\"\"\n",
    "        Calls a function data gets the day from the time column,\n",
    "        outputs whether the day is in the Spring, Summer, Fall or\n",
    "        Winter and creates\n",
    "        \"\"\"\n",
    "        processed_dataframe = self.feature_processing()\n",
    "        season = []\n",
    "\n",
    "        # get the current day of the year\n",
    "        doy = processed_dataframe.iloc[0].name.timetuple().tm_yday\n",
    "\n",
    "        # \"day of year\" ranges for the northern hemisphere\n",
    "        spring = range(80, 172)\n",
    "        summer = range(172, 264)\n",
    "        fall = range(264, 355)\n",
    "        # winter = everything else\n",
    "\n",
    "        for doy in range(len(processed_dataframe)):\n",
    "            if doy in spring:\n",
    "                season.append('Spring')\n",
    "            elif doy in summer:\n",
    "                season.append('Summer')\n",
    "            elif doy in fall:\n",
    "                season.append('Fall')\n",
    "            else:\n",
    "                season.append('Winter')\n",
    "\n",
    "        processed_dataframe['season'] = season\n",
    "        processed_dataframe = processed_dataframe.join(pd.get_dummies(processed_dataframe['season'], prefix='season'))\n",
    "        processed_dataframe.drop('season', axis=1, inplace=True)\n",
    "        return processed_dataframe\n",
    "\n",
    "\n",
    "    #Returns if the day is a weekday or not\n",
    "    def get_weekday(self):\n",
    "        processed_dataframe = self.get_season()\n",
    "\n",
    "        weekday = []\n",
    "\n",
    "        for day in range(len(processed_dataframe)):\n",
    "            if processed_dataframe.iloc[day].name.weekday() < 5:\n",
    "                weekday.append('Weekday')\n",
    "            else:  # 5 Sat, 6 Sun\n",
    "                weekday.append('Weekend')\n",
    "\n",
    "        processed_dataframe['weekday'] = weekday\n",
    "        processed_dataframe = processed_dataframe.join(pd.get_dummies(processed_dataframe['weekday'], prefix='weekday'))\n",
    "        processed_dataframe.drop('weekday', axis=1, inplace=True)\n",
    "        return processed_dataframe\n",
    "\n",
    "    #Returns the period of the day for each row\n",
    "    def get_period_day(self):\n",
    "\n",
    "        processed_dataframe = self.get_weekday()\n",
    "        period = []\n",
    "\n",
    "        for day in range(len(processed_dataframe)):\n",
    "            if 4 <= processed_dataframe.iloc[day].name.hour <= 11:\n",
    "                period.append('Morning')\n",
    "            elif 12 <= processed_dataframe.iloc[day].name.hour <= 19:\n",
    "                period.append('Afternoon')\n",
    "            else:\n",
    "                period.append('Night')\n",
    "\n",
    "        processed_dataframe['period'] = period\n",
    "        processed_dataframe = processed_dataframe.join(pd.get_dummies(processed_dataframe['period'], prefix='period'))\n",
    "        processed_dataframe.drop('period', axis=1, inplace=True)\n",
    "        merge = pd.merge(processed_dataframe,self.target,left_index=True, right_index=True)\n",
    "        return merge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c9171db",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = WeatherEnergy(limit=100,\n",
    "                     offset=0,\n",
    "                     refine='Hauts-de-France',\n",
    "                     target = \"eolien\",\n",
    "                     city=['Heudicourt'],\n",
    "                     years=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0c9ac22",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = data.merged()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d19c7bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df = FeaturePreprocessing(merged_df,\"eolien\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3134035",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = processed_df.get_period_day()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3c4a57f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>standardscaler__temperature_2m</th>\n",
       "      <th>standardscaler__dewpoint_2m</th>\n",
       "      <th>standardscaler__apparent_temperature</th>\n",
       "      <th>standardscaler__pressure_msl</th>\n",
       "      <th>standardscaler__surface_pressure</th>\n",
       "      <th>standardscaler__Wx_10</th>\n",
       "      <th>standardscaler__Wx_100</th>\n",
       "      <th>standardscaler__Wy_10</th>\n",
       "      <th>standardscaler__Wy_100</th>\n",
       "      <th>standardscaler__windgusts_10m</th>\n",
       "      <th>...</th>\n",
       "      <th>powertransformer__direct_radiation</th>\n",
       "      <th>powertransformer__direct_normal_irradiance</th>\n",
       "      <th>powertransformer__diffuse_radiation</th>\n",
       "      <th>powertransformer__et0_fao_evapotranspiration</th>\n",
       "      <th>powertransformer__vapor_pressure_deficit</th>\n",
       "      <th>season_Winter</th>\n",
       "      <th>weekday_Weekday</th>\n",
       "      <th>weekday_Weekend</th>\n",
       "      <th>period_Morning</th>\n",
       "      <th>eolien</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-09-16 08:00:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>390.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-17 08:00:00</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1,841.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     standardscaler__temperature_2m  \\\n",
       "time                                                  \n",
       "2022-09-16 08:00:00                             1.0   \n",
       "2022-09-17 08:00:00                            -1.0   \n",
       "\n",
       "                     standardscaler__dewpoint_2m  \\\n",
       "time                                               \n",
       "2022-09-16 08:00:00                          1.0   \n",
       "2022-09-17 08:00:00                         -1.0   \n",
       "\n",
       "                     standardscaler__apparent_temperature  \\\n",
       "time                                                        \n",
       "2022-09-16 08:00:00                                   1.0   \n",
       "2022-09-17 08:00:00                                  -1.0   \n",
       "\n",
       "                     standardscaler__pressure_msl  \\\n",
       "time                                                \n",
       "2022-09-16 08:00:00                          -1.0   \n",
       "2022-09-17 08:00:00                           1.0   \n",
       "\n",
       "                     standardscaler__surface_pressure  standardscaler__Wx_10  \\\n",
       "time                                                                           \n",
       "2022-09-16 08:00:00                              -1.0                    1.0   \n",
       "2022-09-17 08:00:00                               1.0                   -1.0   \n",
       "\n",
       "                     standardscaler__Wx_100  standardscaler__Wy_10  \\\n",
       "time                                                                 \n",
       "2022-09-16 08:00:00                     1.0                   -1.0   \n",
       "2022-09-17 08:00:00                    -1.0                    1.0   \n",
       "\n",
       "                     standardscaler__Wy_100  standardscaler__windgusts_10m  \\\n",
       "time                                                                         \n",
       "2022-09-16 08:00:00                    -1.0                           -1.0   \n",
       "2022-09-17 08:00:00                     1.0                            1.0   \n",
       "\n",
       "                     ...  powertransformer__direct_radiation  \\\n",
       "time                 ...                                       \n",
       "2022-09-16 08:00:00  ...                                 1.0   \n",
       "2022-09-17 08:00:00  ...                                -1.0   \n",
       "\n",
       "                     powertransformer__direct_normal_irradiance  \\\n",
       "time                                                              \n",
       "2022-09-16 08:00:00                                        -1.0   \n",
       "2022-09-17 08:00:00                                         1.0   \n",
       "\n",
       "                     powertransformer__diffuse_radiation  \\\n",
       "time                                                       \n",
       "2022-09-16 08:00:00                                 -1.0   \n",
       "2022-09-17 08:00:00                                  1.0   \n",
       "\n",
       "                     powertransformer__et0_fao_evapotranspiration  \\\n",
       "time                                                                \n",
       "2022-09-16 08:00:00                                           1.0   \n",
       "2022-09-17 08:00:00                                          -1.0   \n",
       "\n",
       "                     powertransformer__vapor_pressure_deficit  season_Winter  \\\n",
       "time                                                                           \n",
       "2022-09-16 08:00:00                                       1.0              1   \n",
       "2022-09-17 08:00:00                                      -1.0              1   \n",
       "\n",
       "                     weekday_Weekday  weekday_Weekend  period_Morning  eolien  \n",
       "time                                                                           \n",
       "2022-09-16 08:00:00                1                0               1   390.0  \n",
       "2022-09-17 08:00:00                0                1               1 1,841.0  \n",
       "\n",
       "[2 rows x 37 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270baa3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
